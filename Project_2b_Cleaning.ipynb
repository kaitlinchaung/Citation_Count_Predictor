{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and normalization between data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_from_url(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns beautifulsoup object from given URL\n",
    "    \"\"\"\n",
    "    \n",
    "    ua = UserAgent()\n",
    "    user_agent = {'User-agent': ua.random}\n",
    "    response  = requests.get(url, headers = user_agent)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tune white/blacklists to filter out departmental labs and keep data at university-level.\n",
    "inst_whitelist = [\"University\", \"Institute\", \"College\", \"School\", \"Medicine\", \"Hospital\", \"Academy\", \"Medical\", \"School of Medicine\"]\n",
    "inst_blacklist = [\"Department\", \"Laboratory\", \"Faculty\", \"Public Health\", \"Genome\"]\n",
    "\n",
    "def normalize_institution_names(inst):\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalize institution names between scraped data set and Nature Institution stats\n",
    "    \"\"\"\n",
    "    \n",
    "    split = inst.split(',')\n",
    "\n",
    "    first_passes = []\n",
    "    final = []\n",
    "    \n",
    "    ## Restructure University of California names to join campus name with UC name, then proceed.\n",
    "    if \"California\" or \"Carolina\" in inst:\n",
    "        for i in range(len(split[:-1])):\n",
    "            split[i] = split[i].strip()\n",
    "            if split[i] == 'University of California' or split[i] == 'University of North Carolina':\n",
    "                split[i] = \"\".join(split[i] + split.pop(i+1))\n",
    "\n",
    "    for word in split:\n",
    "        res = [ele for ele in inst_whitelist if(ele in word)]\n",
    "        if res:\n",
    "            first_passes.append(word)\n",
    "        for passed in first_passes:\n",
    "            if not any([black in passed for black in inst_blacklist]):\n",
    "                final.append(passed.strip()) \n",
    "    return (\" , \".join(list(set(final))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in scraped data from pages 230-270."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = pd.read_csv(\"paper_data_230_240.csv\")\n",
    "data_set_2 = pd.read_csv(\"paper_data_241_251.csv\")\n",
    "data_set_3 = pd.read_csv(\"paper_data_252_260.csv\")\n",
    "data_set_4 = pd.read_csv(\"paper_data_261_270.csv\")\n",
    "\n",
    "all_data = data_set_1.append([data_set_2,data_set_3,data_set_4])\n",
    "all_data = all_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in working data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data = pd.concat([data_set_1,data_set_2,data_set_3,data_set_4],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up scraped data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns = ['Title','Accesses','Citations','Date','Journal','Author','PI', 'Institution','AllAuthors','Abstract']\n",
    "dates = all_data.Date.str.split(expand=True)\n",
    "dates.columns = ['Day','Month','Year']\n",
    "all_data = pd.concat([all_data,dates], axis=1)\n",
    "all_data.Month = pd.to_datetime(all_data.Month, format='%B').dt.month\n",
    "\n",
    "all_data['NumAuthors'] = all_data.AllAuthors.str.split(',').str.len()\n",
    "all_data['lenTitle'] = all_data.Title.str.split(' ').str.len()\n",
    "\n",
    "all_data = all_data.drop(['Date', 'AllAuthors','Day'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and normalize Impact Factor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact = pd.read_csv('tabula-Journal-Citation-Report-2019.csv')\n",
    "impact.columns = ['Journal', 'ImpactFactor', 'toDelete']\n",
    "impact = impact.drop('toDelete',1)\n",
    "impact = impact[~impact.ImpactFactor.str.contains(\"Not Available\")]\n",
    "impact = impact.fillna(0)\n",
    "\n",
    "impact.Journal = impact.Journal.str.upper()\n",
    "all_data.Journal = all_data.Journal.str.upper()\n",
    "\n",
    "all_data = pd.merge(all_data, impact, on=['Journal'], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize institution names in Nature stats data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_stats = pd.read_csv(\"nature_stats.csv\")\n",
    "nature_stats = nature_stats.drop(['Country'],1)\n",
    "nature_stats.Institution = nature_stats.Institution.str.upper()\n",
    "nature_stats['norm_Institution'] = nature_stats.Institution.str.replace(r'\\([^)]*\\)', '', regex=True).str.strip()\n",
    "nature_stats.norm_Institution = nature_stats.norm_Institution.str.replace(',', '', regex=True)\n",
    "nature_stats.norm_Institution = nature_stats.norm_Institution.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing institution names in working data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['norm_Institution'] = all_data.Institution.apply(normalize_institution_names).str.upper()\n",
    "all_data.norm_Institution = all_data.norm_Institution.replace(r'^\\s*$', np.nan, regex=True)\n",
    "all_data.norm_Institution = all_data.norm_Institution.fillna(all_data.Institution.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fuzzy string match to combine Nature stats with working data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for row in all_data.itertuples():\n",
    "    fuzzy = process.extractOne(row.norm_Institution, nature_stats.norm_Institution,scorer=fuzz.partial_ratio)\n",
    "    nature_match = fuzzy[0]\n",
    "    nature_match_score = fuzzy[1]\n",
    "    \n",
    "    if fuzzy[1] > 90:\n",
    "        match_index = nature_stats[nature_stats.norm_Institution == fuzzy[0]].index.values[0]\n",
    "        scores.append([nature_stats.AC.loc[match_index], nature_stats.FC.loc[match_index]])\n",
    "    else:\n",
    "        scores.append([0, 0])\n",
    "\n",
    "scores_df = pd.DataFrame(scores,columns=['NatureAC','NatureFC'])\n",
    "all_data = pd.concat([all_data,scores_df],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up final working data set and output to flat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[['Citations','Accesses','Month','Year','NumAuthors','lenTitle','ImpactFactor','NatureAC','NatureFC','Title','Abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"working_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
